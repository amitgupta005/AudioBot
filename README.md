# AudioBot ğŸ¤–

**AudioBot** is a full-stack conversational AI application that allows users to interact with an AI assistant using voice. The system features real-time speech recognition, AI-powered text generation, and natural-sounding speech synthesis, all accessible through a modern web interface.

## ğŸš€ Features

- **Real-time Voice Interaction**: Speak directly to the AI using your microphone.
- **Speech-to-Text (STT)**: High-accuracy transcription powered by **Whisper**.
- **AI Chat**: Intelligent responses generated by **Ollama** (Llama 3.2).
- **Text-to-Speech (TTS)**: Natural voice output using **Coqui TTS**.
- **Web Interface**: A clean, responsive UI built with HTML, CSS, and Vanilla JavaScript.
- **WebSocket Communication**: Real-time, bi-directional communication between frontend and backend.
- **Session Management**: Maintains conversation history for context-aware responses.

## ğŸ› ï¸ Tech Stack

### Frontend
- **HTML5**: Structure
- **CSS3**: Styling
- **JavaScript (ES6+)**: Client-side logic and API communication

### Backend
- **Python 3.13+**: Core language
- **FastAPI**: High-performance web framework
- **Uvicorn**: ASGI server
- **websockets**: Real-time communication
- **httpx**: HTTP client for LLM interaction

### AI & ML
- **Ollama**: Llama 3.2 model for text generation
- **Whisper**: Speech recognition
- **Coqui TTS**: Text-to-Speech synthesis

## ğŸ“‚ Project Structure

```
AudioBot/
â”œâ”€â”€ backend/          # FastAPI backend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py       # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ websocket.py  # WebSocket handler
â”‚   â”‚   â”œâ”€â”€ audio.py      # Audio processing (STT/TTS)
â”‚   â”‚   â””â”€â”€ utils.py      # Utility functions
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ frontend/         # Static web files
â”‚   â”œâ”€â”€ index.html    # Main UI
â”‚   â”œâ”€â”€ app.js        # JavaScript logic
â”‚   â””â”€â”€ styles.css    # Styles
â”œâ”€â”€ .venv/            # Virtual environment (optional)
â”œâ”€â”€ README.md         # Project documentation
â””â”€â”€ .gitignore        # Git ignore rules
```

## ğŸš€ Getting Started

### Prerequisites
- **Python 3.13+**
- **Ollama** installed and running (with Llama 3.2 model pulled: `ollama pull llama3.2`)
- **Whisper** model downloaded (will auto-download on first run)
- **Coqui TTS** models (will auto-download on first run)

### Installation

1.  **Clone the repository** (if you haven't already)

2.  **Create and activate a virtual environment** (recommended):
    ```bash
    python -m venv .venv
    # Windows
    .venv\Scripts\activate
    # macOS/Linux
    source .venv/bin/activate
    ```

3.  **Install backend dependencies**:
    ```bash
    cd backend
    pip install -r requirements.txt
    ```

### Running the Application

1.  **Start the backend server**:
    ```bash
    cd backend
    uvicorn app.main:app --reload --host [IP_ADDRESS] --port 8000
    ```

2.  **Start the frontend server**:
    Open a **new terminal** (keep the backend running in the first one)
    ```bash
    cd frontend
    python -m http.server 5500 --bind [IP_ADDRESS]
    ```

3.  **Open the app**:
    Open your web browser and navigate to: `http://[IP_ADDRESS]`

## ğŸ”Œ API Endpoints

The backend exposes the following endpoints:

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/chat` | Send text message and get AI response |
| `GET` | `/ws` | WebSocket for real-time chat |

## ğŸ”„ How It Works

1.  **User Speaks**: User clicks the microphone button in the frontend.
2.  **STT**: Frontend records audio and sends it to the backend.
3.  **Transcription**: Whisper model transcribes the audio to text.
4.  **AI Processing**: The text is sent to Llama 3.2 via Ollama.
5.  **Response Generation**: Llama generates a text response.
6.  **TTS**: The response text is converted to audio using Coqui TTS.
7.  **Playback**: The audio is streamed back to the frontend and played.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open an issue or submit a pull request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
